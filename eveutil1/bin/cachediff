#!/usr/bin/env python

IGNORED_ATTRIBS = [
    # 'attributeIdx', 'maxAttributeID', 'dischargeAttributeID',
    # 'distribution', 'durationAttributeID', 'falloffAttributeID',
    # 'fittingUsageChanceAttributeID', 'npcActivationChanceAttributeID',
    # 'npcUsageChanceAttributeID', 'rangeAttributeID',
    # 'trackingSpeedAttributeID', 'graphicID', 'unitID',
    # 'chargeRechargeTimeID',
    'graphicID', 'iconID', 'unitID', 'dataID'
    ]
import sys
sys.path.append("/home/forcer/Programs/Reverence/active/lib64/python2.6/site-packages/")

import difflib
import optparse
import os
import pickle
import sys

from collections import defaultdict

from reverence import embedfs
from lib import machonet

out = None

def main():
    parser = optparse.OptionParser(usage="%prog [OPTIONS] <OLD> <NEW>",
                                   version="%prog 0.2")
    (options, args) = parser.parse_args()
    if len(args) != 2:
        parser.error("Please specify at least one argument.")
    (olddir, newdir) = args
    global out
    out = HeadlineWriter(sys.stdout)
    do_messages(olddir, newdir)
    do_bulkdata(olddir, newdir)
    do_cache(olddir, newdir)

##################################################################
# messagepackage
def do_messages(olddir, newdir):
    out.set_header("Messagepackage: Messages")
    ddiff(load_messages(olddir),
          load_messages(newdir))

def load_messages(dirname):
    fs = embedfs.EmbedFS(os.path.join(dirname, "resui.stuff"))
    mp = pickle.load(fs.open("res/messagepackage.pickle"))
    (colnames, data) = mp["messages"]
    data = dict((name, NamedDict(name,
                                 zip(colnames, coldata)))
                for (name, coldata) in data.items())
    data["textLabels"] = NamedDict("textLabels",
                                   [(name, value)
                                    for (name, (id, value))
                                    in mp["textLabels"].items()])
    return data

##################################################################
# Bulk data
LOADER = {}

def do_bulkdata(olddir, newdir):
    out("Bulkdata\n")
    out("========\n")
    old_bd = machonet.load(olddir)
    new_bd = machonet.load(newdir)

    keys = uniq([key for key in old_bd.keys() 
                 if hasattr(key, "startswith")
                 and key.startswith('config.')]
                +
                [key for key in new_bd.keys() 
                 if hasattr(key, "startswith")
                 and key.startswith('config.')])
    keys.sort()
    for key in keys:
        out.set_header(key, "-")
        if key not in old_bd:
            out("New bulkdata file.\n")
        elif key not in new_bd:
            out("Bulkdata file removed.\n")
        elif key not in LOADER:
            out("No loader for bulkdata file.\n")
        else:
            ddiff(LOADER[key](old_bd[key], old_bd),
                  LOADER[key](new_bd[key], new_bd))
        out.end_section()

########
# Loader
def loader(name):
    def decorate(func):
        LOADER[name] = func
        return func
    return decorate

@loader('config.BulkData.types')
def bdl_types(data, bulkdata):
    result = datadict(data, key="typeID",
                      get_name=lambda row: ("%s (typeID %s)" %
                                            (row["typeName"],
                                             row["typeID"])))
    add_attributes(result, bulkdata)
    add_effects(result, bulkdata)
    add_materials(result, bulkdata)
    return result

def add_attributes(result, bulkdata):
    da = bulkdata['config.BulkData.dgmattribs']
    aname = {}
    for row in datadict(da, 'attributeID', 'attributeName').values():
        aname[row["attributeID"]] = row["attributeName"]
    dta = bulkdata['config.BulkData.dgmtypeattribs'].obj
    for (typeid, attributeid, value) in dta:
        if typeid not in result:
            nd = NamedDict("??? (typeID %s from attributes)" % (typeid,))
            result[typeid] = nd
        result[typeid][aname.get(attributeid, str(attributeid))] = value

def add_effects(result, bulkdata):
    de = bulkdata['config.BulkData.dgmeffects']
    ename = {}
    for row in datadict(de, 'effectID', 'effectName').values():
        ename[row.effectID] = row.effectName
    det = bulkdata['config.BulkData.dgmtypeeffects'].obj
    for (typeid, effectid, isdefault) in det:
        if typeid not in result:
            nd = NamedDict("??? (typeID %s from effects)" % (typeid,))
            result[typeid] = nd
        result[typeid][ename[effectid]] = isdefault

def add_materials(result, bulkdata):
    typename = get_typenames(bulkdata)
    return
    if 'config.BulkData.ramtypematerials' in bulkdata:
        rtm = bulkdata['config.BulkData.ramtypematerials'].obj
    elif 'config.BulkData.invtypematerials' in bulkdata:
        rtm = bulkdata['config.BulkData.invtypematerials'].obj
    else:
        return
    for (typeid, materialtypeid, quantity) in rtm:
        if typeid not in result:
            nd = NamedDict("??? (typeID %s from materials)" % (typeid,))
            result[typeid] = nd
        result[typeid][typename[materialtypeid]] = quantity

@loader('config.BulkData.bptypes')
def bdl_bptypes(data, bulkdata):
    typename = get_typenames(bulkdata)
    actname = get_actnames(bulkdata)

    bps = datadict(data, key="blueprintTypeID",
                   get_name=lambda row: (
            typename.get(row["blueprintTypeID"],
                         "<TypeID %s>" % row["blueprintTypeID"])))
    rta = defaultdict(lambda: [])
    for row in bulkdata['config.BulkData.ramtyperequirements'].obj:
        rta[row.typeID].append(row)
    for bp in bps.values():
        for mat in rta.get(bp['blueprintTypeID'], []):
            tname = typename[mat.requiredTypeID]
            aname = actname[mat.activityID]
            bp["%s (%s)" % (tname, aname)] = ("%s (%s, recycle: %s)" %
                                              (mat.quantity, mat.damagePerJob,
                                               mat.recycle))
    return bps

@loader('config.Attributes')
def bdl_attributes(data, bulkdata):
    return datadict(data, 'attributeID', 'attributeName')

@loader('config.Bloodlines')
def bdl_bloodlines(data, bulkdata):
    return datadict(data, 'bloodlineID', 'bloodlineName')

@loader('config.BulkData.allianceshortnames')
def bdl_allianceshortnames(data, bulkdata):
    return datadict(data, 'allianceshortnameID', 'allianceshortnameID')

@loader('config.BulkData.billtypes')
def bdl_billtypes(data, bulkdata):
    return datadict(data, 'billTypeID', 'billTypeName')

@loader('config.BulkData.categories')
def bdl_categories(data, bulkdata):
    return datadict(data, 'categoryID', 'categoryName')

@loader('config.BulkData.certificaterelationships')
def bdl_certificaterelationships(data, bulkdata):
    return datadict(data, 'relationshipID', 'relationshipID')

@loader('config.BulkData.certificates')
def bdl_certificates(data, bulkdata):
    # FIXME! Needs better names
    return datadict(data, 'certificateID', 'certificateID')

@loader('config.BulkData.dgmattribs')
def bdl_dgmattribs(data, bulkdata):
    return datadict(data, 'attributeID', 'attributeName')

@loader('config.BulkData.dgmeffects')
def bdl_dgmeffects(data, bulkdata):
    return datadict(data, 'effectID', 'effectName')

@loader('config.BulkData.dgmtypeattribs')
def bdl_dgmtypeattribs(data, bulkdata):
    # This is handled by the type handler. Just ignore.
    return {}

@loader('config.BulkData.dgmtypeeffects')
def bdl_dgmtypeeffects(data, bulkdata):
    # This is handled by the type handler. Just ignore.
    return {}

@loader('config.BulkData.graphics')
def bdl_graphics(data, bulkdata):
    # FIXE! Needs a better name
    # Use urlweb or url3d
    return datadict(data, 'graphicID', 'graphicID')

@loader('config.BulkData.groups')
def bdl_groups(data, bulkdata):
    return datadict(data, 'groupID', 'groupName')

@loader('config.BulkData.invmetatypes')
def bdl_invmetatypes(data, bulkdata):
    # FIXME! Move this to invtypes
    return datadict(data, 'typeID', 'typeID')

@loader('config.BulkData.invtypereactions')
def bdl_invtypereactions(data, bulkdata):
    typename = get_typenames(bulkdata)
    result = {}
    itr = bulkdata['config.BulkData.invtypereactions'].obj
    for (reactionTypeID, is_input, typeID, quantity) in itr:
        if reactionTypeID not in result:
            result[reactionTypeID] = NamedDict(typename[reactionTypeID])
        result[reactionTypeID]["%s (%s)" %
                               (typename[typeID],
                                "in" if is_input else "out")] = quantity
    return result

@loader('config.BulkData.locations')
def bdl_locations(data, bulkdata):
    return datadict(data, 'locationID', 'locationName')

@loader('config.BulkData.locationscenes')
def bdl_locationscenes(data, bulkdata):
    return datadict(data, 'locationID', 'locationID')

@loader('config.BulkData.locationwormholeclasses')
def bdl_locationwormholeclasses(data, bulkdata):
    return datadict(data, 'locationID', 'locationID')

@loader('config.BulkData.mapcelestialdescriptions')
def bdl_mapcelestialdescriptions(data, bulkdata):
    return datadict(data, 'celestialID', 'celestialID')

@loader('config.BulkData.metagroups')
def bdl_metagroups(data, bulkdata):
    return datadict(data, 'metaGroupID', 'metaGroupName')

@loader('config.BulkData.owners')
def bdl_owners(data, bulkdata):
    return datadict(data, 'ownerID', 'ownerName')

@loader('config.BulkData.ramactivities')
def bdl_ramactivities(data, bulkdata):
    return datadict(data, 'activityID', 'activityName')

@loader('config.BulkData.ramaltypes')
def bdl_ramaltypes(data, bulkdata):
    # FIXME!
    # Incorporate:
    # 'config.BulkData.ramaltypesdetailpercategory'
    # 'config.BulkData.ramaltypesdetailpergroup'
    return datadict(data, 'assemblyLineTypeID', 'assemblyLineTypeName')

@loader('config.BulkData.ramaltypesdetailpercategory')
def bdl_ramaltypesdetailpercategory(data, bulkdata):
    # Handled by assemblylines
    return {}

@loader('config.BulkData.ramaltypesdetailpergroup')
def bdl_ramaltypesdetailpergroup(data, bulkdata):
    # Handled by assemblylines
    return {}

@loader('config.BulkData.ramcompletedstatuses')
def bdl_ramcompletedstatuses(data, bulkdata):
    return datadict(data, 'completedStatusID', 'completedStatusName')

@loader('config.BulkData.ramtypematerials')
def bdl_ramtypematerials(data, bulkdata):
    # Done in types
    return {}

@loader('config.BulkData.ramtyperequirements')
def bdl_ramtyperequirements(data, bulkdata):
    # Done in bptypes
    return {}

@loader('config.BulkData.schematics')
def bdl_schematics(data, bulkdata):
    return datadict(data, 'schematicID', 'schematicName')

@loader('config.BulkData.schematicstypemap')
def bdl_schematics(data, bulkdata):
    # FIXME! Mapping, should be handled in schematics
    # return datadict(data, 'schematicID', 'schematicID')
    return {}

@loader('config.BulkData.schematicspinmap')
def bdl_schematics(data, bulkdata):
    # return datadict(data, 'schematicID', 'schematicID')
    return {}

@loader('config.BulkData.shiptypes')
def bdl_shiptypes(data, bulkdata):
    typename = get_typenames(bulkdata)
    data = datadict(data, 'shipTypeID',
                    get_name=lambda row: typename[row["shipTypeID"]])
    for row in data.values():
        for (tn, tid) in [("shipTypeName", "shipTypeID"),
                          ("weaponTypeName", "weaponTypeID"),
                          ("miningTypeName", "miningTypeID"),
                          ("skillTypeName", "skillTypeID")]:
            if row[tid] != 0:
                row[tn] = typename[row[tid]]
    return data

@loader('config.BulkData.sounds')
def bdl_sounds(data, bulkdata):
    return datadict(data, 'soundID', 'soundID')

@loader('config.BulkData.tickernames')
def bdl_tickernames(data, bulkdata):
    return datadict(data, 'corporationID', 'tickerName')

@loader('config.BulkData.units')
def bdl_units(data, bulkdata):
    return datadict(data, 'unitID', 'unitName')

@loader('config.Flags')
def bdl_Flags(data, bulkdata):
    return datadict(data, 'flagID', 'flagName')

@loader('config.InvContrabandTypes')
def bdl_InvContrabandTypes(data, bulkdata):
    typename = get_typenames(bulkdata)
    return datadict(data,
                    get_name=lambda row: typename[row["typeID"]],
                    get_key=lambda row: (row["typeID"],
                                         row["factionID"]))

@loader('config.Races')
def bdl_Races(data, bulkdata):
    return datadict(data, 'raceID', 'raceName')

@loader('config.StaticLocations')
def bdl_StaticLocations(data, bulkdata):
    result = {}
    obj = data.obj
    if hasattr(obj, 'lines'):
        lines = obj.lines
    else:
        lines = obj
    for (locationID, locationName, x, y, z) in lines:
        result[locationID] = NamedDict(locationName,
                                       {'locationID': locationID,
                                        'locationName': locationName,
                                        'x': x, 'y': y, 'z': z})
    return result

@loader('config.StaticOwners')
def bdl_StaticOwners(data, bulkdata):
    result = {}
    for row in data.obj:
        if hasattr(row, '__class__') and row.__class__.__name__ == 'DBRow':
            result[row.ownerID] = NamedDict(row.ownerName,
                                            dict(zip(row.__header__.Keys(),
                                                     row)))
        else:
            result[row.ownerID] = NamedDict(row.ownerName,
                                            dict(zip(row.header, row.line)))
    return result

@loader('config.Units')
def bdl_Units(data, bulkdata):
    return datadict(data, 'unitID', 'unitName')

# Loader Helper
def datadict(data, key=None, name=None,
             get_key=None, get_name=None):
    if get_name is None:
        if name is None:
            out("ERR: Need to specify name or get_name\n")
        get_name = lambda elt: elt[name]
    if get_key is None:
        if key is None:
            out("ERR: Need to specify unique or get_unique\n")
        get_key = lambda elt: elt[key]
    result = {}
    for row in data.table():
        pk = get_key(row)
        if pk in result:
            out("ERR: Key %s occurs multiple times.\n" % pk)
        result[pk] = NamedDict(get_name(row), row.dict())
    return result

def get_typenames(bulkdata):
    return dict((row.typeID, row.typeName)
                for row in bulkdata['config.BulkData.types'].obj)

def get_actnames(bulkdata):
    return dict((row.activityID, row.activityName)
                for row
                in bulkdata['config.BulkData.ramactivities'].obj)

##################################################################
# Cache
def do_cache(olddir, newdir):
    out("Cache\n")
    out("=====\n")
    old_bd = machonet.load(olddir)
    new_bd = machonet.load(newdir)

    for call in [('agentMgr', 'GetAgents'),
                 ('billMgr', 'GetBillTypes')]:
        out.set_header("%s.%s" % call, "-")
        if call not in old_bd:
            out("Not in old cache.\n")
            continue
        if call not in new_bd:
            out("Not in new cache.\n")
            continue
        ddiff(LOADER[call](old_bd[call], old_bd),
              LOADER[call](new_bd[call], new_bd))
        out.end_section()

@loader(('agentMgr', 'GetAgents'))
def cl_GetAgents(obj, macho):
    agentname = dict((owner['ownerID'], owner['ownerName'])
                     for owner in macho['config.StaticOwners'].obj)
    locname = dict((loc['locationID'], loc['locationName'])
                   for loc in macho['config.StaticLocations'].obj)
    return datadict(obj, 'agentID',
                    get_name=lambda row: "%s (%s)" % (
            agentname[row['agentID']],
            locname.get(row['stationID'], "in space / %s" % row['stationID'])))

@loader(('billMgr', 'GetBillTypes'))
def cl_GetBillTypes(obj, macho):
    return datadict(obj, 'billTypeID', 'billTypeName')

##################################################################
# Helper functions

def ddiff(old, new):
    keys = uniq(old.keys() + new.keys())
    keys.sort()
    for key in keys:
        ddiff_single(old.get(key, None),
                     new.get(key, None))

def ddiff_single(old, new):
    if old is None:
        out("* ADD: %s\n" % (new.name,))
        keys = new.keys()
        keys.sort(lambda a, b: cmp(a.lower(), b.lower()))
        for key in keys:
            out("- %s: %r\n" % (key, new[key]))
        out("\n")
    elif new is None:
        out("* DEL: %s\n" % (old.name,))
        keys = old.keys()
        keys.sort(lambda a, b: cmp(a.lower(), b.lower()))
        for key in keys:
            out("- %s: %r\n" % (key, old[key]))
        out("\n")
    else:
        keys = uniq(old.keys() + new.keys())
        keys.sort(lambda a, b: cmp(a.lower(), b.lower()))
        changes = []
        for name in keys:
            if name in IGNORED_ATTRIBS:
                continue
            oldv = old.get(name, None)
            newv = new.get(name, None)
            if oldv != newv:
                changes.append((name, oldv, newv))
        if len(changes) > 0:
            out("* CHG: %s\n" % (new.name,))
            for (name, oldv, newv) in changes:
                printchange(name, oldv, newv)
            out("\n")

def printchange(name, oldv, newv):
    if (type(oldv) == unicode and
        type(newv) == unicode and
        max(len(oldv), len(newv)) > 32):

        out("- %s: (diff)\n" % name)
        diffstring(oldv, newv)
    else:
        out("- %s: %r -> %r\n" % (name, oldv, newv))

def diffstring(old, new):
    a = old.split()
    b = new.split()
    sm = difflib.SequenceMatcher(None, a, b)
    for (op, i1, i2, j1, j2) in sm.get_opcodes():
        if op == 'replace':
            out("  ~ %r -> %r\n" % (" ".join(a[i1:i2]),
                                    " ".join(b[j1:j2])))
        elif op == 'delete':
            out("  - %r\n" % (" ".join(a[i1:i2]),))
        elif op == 'insert':
            out("  + %r\n" % (" ".join(b[j1:j2]),))
        elif op == 'equal':
            out("  = %r\n" % (" ".join(b[j1:j2]),))
        else:
            out("  ? %r\n" % (op,))

def uniq(l):
    return dict((e, True) for e in l).keys()

class NamedDict(dict):
    def __init__(self, name, *args, **kwargs):
        self.name = name
        super(NamedDict, self).__init__(*args, **kwargs)

    def __getattr__(self, name):
        return self[name]

class HeadlineWriter(object):
    def __init__(self, f):
        self.f = f
        self.name = None
        self.underline = None
        self.header_done = True

    def __call__(self, s):
        if not self.header_done:
            self.f.write(self.name)
            self.f.write("\n")
            self.f.write(self.underline * len(self.name))
            self.f.write("\n")
            self.header_done = True
        self.f.write(s.encode("utf-8"))

    def set_header(self, name, underline="="):
        self.name = name
        self.underline = underline
        self.header_done = False

    def end_section(self):
        if self.header_done:
            self.f.write("\n")

if __name__ == '__main__':
    main()
