#!/usr/bin/env python

import sys ; sys.path.append("/home/forcer/Projects/twf/dev/")

import daemon
import datetime
import logging
import os
import Queue
import random
import re
import simplejson
import threading
import time
import urllib

BASEDIR = "/home/forcer/Depot/killboards/evearena/"
LOGFILE = os.path.join(BASEDIR, "log.txt")
MAXTHREADS = 1
DELAY = [30, 60*10] # in seconds

kmrx = re.compile('<fieldset><textarea rows="20" cols="20">((?:.|\n)*?)'
                  '</textarea></fieldset>',
                  re.MULTILINE)

log = None

def main():
    global log
    with daemon.DaemonContext():
        logging.basicConfig(filename=LOGFILE,
                            format="%(asctime)-15s %(levelname)s %(message)s",
                            level=logging.DEBUG)
        log = logging.getLogger('getarena')
        try:
            run()
        except Exception as e:
            log.error("Error %s: %s" %
                      (e.__class__.__name__, str(e)))

def run():
    log.info("getarena starting")
    q = Queue.Queue(1)
    threads = []
    for i in range(0, MAXTHREADS):
        t = Fetcher(q)
        t.start()
        threads.append(t)
    lastday = -1
    kids = []
    for kid in getkids():
        q.put(kid)

def synopsis(page=None):
    base = "http://www.eve-arena.com/ajax/synopsis.ajax.php"
    args = {'kills': "true",
            'limit': "100",
            'regions': "10000030,10000042,10000028,10000011"}
    if page is not None and page > 1:
        args['offset'] = str((page-1) * 100)
    return base + "?" + urllib.urlencode(args)

def getkids():
    last = datetime.datetime.now()
    page = 1
    while True:
        now = datetime.datetime.now()
        if (now - last).days > 1:
            log.info("Running for a day, checking newest kills")
            page = 1
            last = now
        try:
            data = simplejson.load(urlopen(synopsis(page)))
        except Exception:
            data = None
        if data is None or "encounters" not in data or data["encounters"] is None:
            log.warning("Bad JSON data, no encounters?")
            time.sleep(60)
            continue
        for encounter in data["encounters"]:
            kid = long(encounter["id"])
            fname = kidfile(kid)
            if os.path.exists(fname):
                continue
            dname = os.path.dirname(fname)
            if not os.path.isdir(dname):
                os.mkdir(dname)
            yield kid
        page += 1

def kidfile(kid):
    n = "%07i.txt" % kid
    d = n[:3]
    return os.path.join(BASEDIR, d, n)

class Fetcher(threading.Thread):
    def __init__(self, queue):
        self.q = queue
        super(Fetcher, self).__init__()
        self.daemon = True

    def run(self):
        while True:
            try:
                kmid = self.q.get()
                log.info("Downloading kid %i" % kmid)
                data = urlopen("http://www.eve-arena.com/encounters/%i"
                               % kmid).read()
                m = kmrx.search(data)
                if m is None:
                    log.warning("Bad km %i" % kmid)
                    return
                file(kidfile(kmid), "w").write(m.group(1))
                time.sleep(random.randint(*DELAY))
            except Exception as e:
                log.error("Exception %s during fetch: %s" %
                          (e.__class__.__name__, str(e)))
                time.sleep(30)

def eta(curr, total, duration):
    totalseconds = int((duration.seconds / float(curr)) * (total-curr))
    s = []
    for (cutoff, unit) in [(60*60, "h"), (60, "m")]:
        if totalseconds > cutoff:
            s.append("%i%s" % (totalseconds / cutoff, unit))
            totalseconds %= cutoff
    s.append("%is" % totalseconds)
    return " ".join(s)

def urlopen(url):
    while True:
        try:
            return urllib.urlopen(url)
        except Exception:
            time.sleep(30)

if __name__ == '__main__':
    main()
